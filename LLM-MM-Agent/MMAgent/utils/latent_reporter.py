"""
Latent Reporter: Post-Processing Research Journal Generator

This module implements an observer-pattern reporter that reads execution traces
and generates MCM/ICM-style research journal entries using LLM.

Key Features:
- Reads trace.jsonl for comprehensive event analysis
- Stage-level retrospection (problem_analysis, mathematical_modeling)
- Error diagnosis and solution documentation
- Result validation and sensitivity discussion
- Automatic chart embedding with generated captions

Author: MM-Agent Team
Date: 2026-01-18 (Refactored for chat with claude3.txt proposal)
"""

import json
import os
import sys
import io
from pathlib import Path
import logging
from datetime import datetime
from typing import Optional, List, Dict, Any

# [FIX 2026-01-18] Windows Console Encoding Fix
# Set UTF-8 encoding for stdout/stderr on Windows to display emoji characters
# This prevents UnicodeEncodeError when printing emoji (ğŸ›‘, ğŸŸ¢, ğŸ”´) in error messages
if sys.platform == 'win32':
    try:
        # Reconfigure stdout and stderr with UTF-8 encoding
        # Use 'replace' error handler to prevent crashes on unencodable characters
        if hasattr(sys.stdout, 'buffer'):
            sys.stdout = io.TextIOWrapper(
                sys.stdout.buffer,
                encoding='utf-8',
                errors='replace',
                line_buffering=sys.stdout.line_buffering
            )
        if hasattr(sys.stderr, 'buffer'):
            sys.stderr = io.TextIOWrapper(
                sys.stderr.buffer,
                encoding='utf-8',
                errors='replace',
                line_buffering=sys.stderr.line_buffering
            )
    except Exception as e:
        # If reconfiguration fails, continue silently (non-critical)
        pass

# Import journal prompts
from MMAgent.prompt import journal_prompts

logger = logging.getLogger("LatentReporter")


class LatentReporter:
    """
    æ½œä¼æŠ¥å‘Šå™¨ï¼šè§‚å¯Ÿè€…æ¨¡å¼çš„ç§‘ç ”æ—¥è®°ç”Ÿæˆå™¨

    æ ¸å¿ƒèŒè´£ï¼š
    1. è§‚å¯Ÿ Agent æ‰§è¡Œè¿‡ç¨‹ï¼ˆè¯»å– trace.jsonlï¼‰
    2. è°ƒç”¨ LLM å°†æŠ€æœ¯æ—¥å¿—è½¬åŒ–ä¸ºç§‘ç ”é£æ ¼çš„å™è¿°
    3. è‡ªåŠ¨åµŒå…¥å›¾è¡¨ç­‰äº§ç‰©
    4. ç”Ÿæˆ Markdown æ ¼å¼çš„å®éªŒæ—¥è®°

    Usage:
        reporter = LatentReporter(output_dir, llm_client, tracker_file="path/to/trace.jsonl")
        reporter.reflect_on_stage("problem_analysis")
        reporter.reflect_on_stage("mathematical_modeling")
        reporter.diagnose_failure("KeyError: 'YEAR'")
        reporter.summarize_results(solution_dict)
    """

    def __init__(self, output_dir, llm_client, tracker_file=None):
        """
        åˆå§‹åŒ–æ½œä¼æŠ¥å‘Šå™¨

        Args:
            output_dir: ä¸»è¾“å‡ºç›®å½• (ä¾‹å¦‚ output/MM-Agent/Task_Timestamp/)
            llm_client: LLM å®ä¾‹ (ç”¨äºç”Ÿæˆå™è¿°)
            tracker_file: trace.jsonl çš„è·¯å¾„ (å¯é€‰ï¼Œé»˜è®¤è‡ªåŠ¨å®šä½)
        """
        # --- è·¯å¾„ä¿®æ­£é€»è¾‘ (åé€’å½’ Bug ä¿®å¤) ---
        base_path = Path(output_dir)
        if base_path.name in ["Workspace", "Memory", "Report", "logs", "code", "json"]:
            self.root_dir = base_path.parent
        else:
            self.root_dir = base_path

        self.report_dir = self.root_dir / "Report"
        self.report_dir.mkdir(parents=True, exist_ok=True)

        # å®šä¹‰æ ¸å¿ƒæ–‡ä»¶è·¯å¾„
        self.journal_path = self.report_dir / "01_Research_Journal.md"

        # è‡ªåŠ¨å®šä½ trace.jsonl (å¦‚æœæœªä¼ å…¥)
        if tracker_file:
            self.trace_file = Path(tracker_file)
        else:
            self.trace_file = self.root_dir / "Memory" / "logs" / "trace.jsonl"

        self.llm = llm_client
        self.logger = logging.getLogger("main")

        # åˆå§‹åŒ–æ—¥è®°æ–‡ä»¶å¤´
        if not self.journal_path.exists():
            self._init_journal()

    def _init_journal(self):
        """å†™å…¥æ—¥è®°çš„å¤´éƒ¨ä¿¡æ¯"""
        header = f"""# 2025_C æ•°å­¦å»ºæ¨¡ç§‘ç ”æ—¥è®°
**Task ID**: Auto-Generated
**Status**: In Progress

> æœ¬æ–‡æ¡£ç”± Latent LLM å®æ—¶ç”Ÿæˆï¼Œè®°å½•äº† Agent çš„æ€ç»´å®éªŒè¿‡ç¨‹ã€‚

---

## 1. Problem Background
[å¾…ç”Ÿæˆ]

"""
        try:
            with open(self.journal_path, 'w', encoding='utf-8') as f:
                f.write(header)
            self.logger.info(f"Research journal initialized: {self.journal_path}")
        except Exception as e:
            self.logger.error(f"Failed to initialize journal: {e}")

    def _read_recent_events(self, k=50) -> List[Dict[str, Any]]:
        """
        è¯»å– trace.jsonl çš„æœ€å k è¡Œ

        Args:
            k: è¯»å–çš„è¡Œæ•°

        Returns:
            List[Dict]: äº‹ä»¶åˆ—è¡¨
        """
        events = []
        if not self.trace_file.exists():
            self.logger.warning(f"Trace file not found: {self.trace_file}")
            return []

        try:
            with open(self.trace_file, 'r', encoding='utf-8') as f:
                lines = f.readlines()
                # ç®€å•ç­–ç•¥ï¼šå–æœ€è¿‘çš„ä¸Šä¸‹æ–‡
                # å®é™…ç”Ÿäº§ä¸­å¯æ ¹æ® stage è¿‡æ»¤
                for line in lines[-k:]:
                    try:
                        events.append(json.loads(line))
                    except json.JSONDecodeError:
                        continue
        except Exception as e:
            self.logger.warning(f"Failed to read trace events: {e}")

        return events

    # ========================================================================
    # [TRUTH MODE] CRITICAL FIX: _read_crash_site() for CRITICAL_FAILURE events
    # ========================================================================

    def _read_crash_site(self) -> List[Dict[str, Any]]:
        """
        ã€Truth Modeã€‘ä¸“é—¨è¯»å–CRITICAL_FAILUREäº‹ä»¶ï¼Œå®šä½å´©æºƒç‚¹

        ä¸_read_recent_events()ä¸åŒï¼Œæ­¤æ–¹æ³•åªè¯»å–"type": "CRITICAL_FAILURE"çš„äº‹ä»¶ï¼Œ
        è¿™äº›äº‹ä»¶åŒ…å«å®Œæ•´çš„Python tracebackï¼Œæ˜¯è¯Šæ–­Pipelineå´©æºƒçš„å…³é”®è¯æ®ã€‚

        Returns:
            List[Dict]: æ‰€æœ‰CRITICAL_FAILUREäº‹ä»¶çš„dataå­—æ®µåˆ—è¡¨

        Example:
            >>> crashes = reporter._read_crash_site()
            >>> if crashes:
            ...     last_crash = crashes[-1]
            ...     print(last_crash['error_type'])  # 'KeyError'
            ...     print(last_crash['traceback'])   # å®Œæ•´çš„å †æ ˆä¿¡æ¯
        """
        failures = []
        if not self.trace_file.exists():
            self.logger.error("Trace file not found for crash analysis")
            return []

        try:
            with open(self.trace_file, 'r', encoding='utf-8') as f:
                for line in f:
                    try:
                        event = json.loads(line)
                        # åªå…³å¿ƒCRITICAL_FAILUREç±»å‹çš„äº‹ä»¶
                        if event.get('type') == 'CRITICAL_FAILURE':
                            # æå–dataå­—æ®µï¼ŒåŒ…å«tracebackç­‰ä¿¡æ¯
                            failures.append(event.get('data', {}))
                    except json.JSONDecodeError:
                        # è·³è¿‡æ ¼å¼é”™è¯¯çš„è¡Œ
                        continue
        except Exception as e:
            self.logger.error(f"Failed to read crash site from trace file: {e}")

        return failures

    def _append_markdown(self, content: str):
        """
        è¿½åŠ å†…å®¹åˆ°æ—¥è®°æ–‡ä»¶

        Args:
            content: Markdown æ ¼å¼çš„å†…å®¹
        """
        try:
            with open(self.journal_path, 'a', encoding='utf-8') as f:
                f.write(f"\n\n{content}\n")
            self.logger.info(f"LatentReporter updated journal at {self.journal_path}")
        except Exception as e:
            self.logger.error(f"Failed to append to journal: {e}")

    # ========================================================================
    # æ ¸å¿ƒæ¥å£ï¼šé˜¶æ®µæ€§å¤ç›˜
    # ========================================================================

    def reflect_on_stage(self, stage_name: str):
        """
        é˜¶æ®µæ€§å¤ç›˜ï¼šè¯»å– trace.jsonl å¹¶ç”Ÿæˆé˜¶æ®µåˆ†æ

        Args:
            stage_name: é˜¶æ®µåç§°
                - "problem_analysis": é—®é¢˜åˆ†æé˜¶æ®µ
                - "mathematical_modeling": æ•°å­¦å»ºæ¨¡é˜¶æ®µ
        """
        self.logger.info(f"LatentReporter reflecting on stage: {stage_name}")

        # 1. è¯»å–æœ€è¿‘çš„äº‹ä»¶
        events = self._read_recent_events(k=100)  # è¯»å–è¶³å¤Ÿçš„ä¸Šä¸‹æ–‡
        events_str = json.dumps(events, indent=2, ensure_ascii=False)

        # 2. æ ¹æ®é˜¶æ®µé€‰æ‹© prompt
        if stage_name == "problem_analysis":
            prompt = journal_prompts.STAGE_REFLECTION_ANALYSIS.format(events=events_str)
            title = "## 2. Problem Restatement & Hypotheses"
        elif stage_name == "mathematical_modeling":
            prompt = journal_prompts.STAGE_REFLECTION_MODELING.format(events=events_str)
            title = "## 3. Modeling Process"
        else:
            self.logger.warning(f"Unknown stage: {stage_name}, skipping reflection")
            return

        # 3. è°ƒç”¨ LLM ç”Ÿæˆå†…å®¹
        try:
            response = self.llm.chat(
                prompt,
                system_prompt=journal_prompts.SYSTEM_PROMPT
            )
            self._append_markdown(f"{title}\n\n{response}")
            self.logger.info(f"Stage reflection completed: {stage_name}")
        except Exception as e:
            self.logger.error(f"Failed to generate stage reflection: {e}")
            # Fallback: å†™å…¥åŸå§‹äº‹ä»¶
            self._append_markdown(f"{title}\n\n[LLM Generation Failed: {e}]\n\n**Raw Events**:\n```json\n{events_str[:500]}\n```")

    # ========================================================================
    # æ ¸å¿ƒæ¥å£ï¼šé”™è¯¯è¯Šæ–­
    # ========================================================================

    def diagnose_failure(self, fallback_error_msg: str):
        """
        ã€Truth Modeã€‘å½“Pipelineå´©æºƒæ—¶è°ƒç”¨ï¼Œè¿›è¡Œæ³•åŒ»å¼å°¸æ£€åˆ†æ

        è¿™æ˜¯å®ç°"æ—¥å¿—ä¸è¯´è°"çš„æ ¸å¿ƒæ–¹æ³•ã€‚å®ƒä¼šï¼š
        1. è¯»å–trace.jsonlä¸­çš„CRITICAL_FAILUREäº‹ä»¶ï¼ˆåŒ…å«å®Œæ•´tracebackï¼‰
        2. å°†tracebackå–‚ç»™LLMè¿›è¡Œåˆ†æ
        3. åœ¨Research Journalä¸­ç”Ÿæˆè¯¦ç»†çš„é”™è¯¯æŠ¥å‘Š
        4. é™„åŠ åŸå§‹å †æ ˆä¿¡æ¯ä¾›äººå·¥éªŒè¯

        Args:
            fallback_error_msg: å¦‚æœæ‰¾ä¸åˆ°trace.jsonlæ—¶çš„å¤‡ç”¨é”™è¯¯ä¿¡æ¯
                                (é€šå¸¸æ˜¯main.py exceptå—æ•è·çš„str(e))

        Example:
            >>> try:
            ...     run_pipeline()
            ... except Exception as e:
            ...     reporter.diagnose_failure(str(e))
        """
        self.logger.warning(">>> LatentReporter: Starting Forensic Analysis (æ³•åŒ»å¼å°¸æ£€)...")

        # 1. è¯»å–æœ€è¯¦ç»†çš„å †æ ˆ
        failures = self._read_crash_site()

        # 2. æ„å»ºä¸Šä¸‹æ–‡
        context = ""
        if failures:
            # âœ… æ‰¾åˆ°äº†è®°å½•åœ¨æ¡ˆçš„åº•å±‚é”™è¯¯
            last_fail = failures[-1]
            context = f"""
!!! DETECTED CRITICAL FAILURE IN LOGS !!!

**Error Type**: {last_fail.get('error_type')}
**Error Message**: {last_fail.get('error_message')}
**Stage**: {last_fail.get('stage')}

--- RAW TRACEBACK (The Truth) ---
{last_fail.get('traceback')}
---------------------------------

**Context Snippet**:
{last_fail.get('context_snippet', 'No context available')}

**Analysis Time**: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}
"""
            self.logger.info(f"Found {len(failures)} critical failure(s) in trace, analyzing the most recent one")
        else:
            # âŒ æ—¥å¿—é‡Œæ²¡è®°ä¸‹æ¥ï¼Ÿç¨‹åºå´©æºƒå¾—å¤ªå¿«ï¼Œæˆ–è€…Trackerè¢«ç»•è¿‡äº†
            context = f"""
!!! SYSTEM CRASH (UNLOGGED) !!!

The system crashed without writing a structured error log to trace.jsonl.

**Python Exception detected by Main Loop**:
{fallback_error_msg}

**Possible Causes**:
1. tracker.log_error() was not called before exception bubbled up
2. Exception occurred before tracker initialization
3. File system error prevented writing to trace.jsonl
4. Exception occurred in ExecutionTracker.log_error() itself

**Analysis Time**: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}

**Note**: Analysis is based on fallback error message only, which may be incomplete.
"""
            self.logger.warning("No CRITICAL_FAILURE events found in trace, using fallback error message")

        # 3. è°ƒç”¨LLMè¿›è¡Œåˆ†æ
        prompt = journal_prompts.ERROR_DIAGNOSIS.format(events=context)

        try:
            response = self.llm.chat(
                prompt,
                system_prompt=journal_prompts.SYSTEM_PROMPT
            )

            # 4. ç‹ ç‹ åœ°å†™å…¥Markdownï¼Œç”¨çº¢è‰²è­¦å‘Š
            with open(self.journal_path, 'a', encoding='utf-8') as f:
                f.write(f"\n\n## ğŸ›‘ FATAL ERROR ANALYSIS\n")
                f.write(f"> **Status**: MISSION FAILED\n")
                f.write(f"> **Analysis Time**: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
                f.write(f"> **Crash Events Found**: {len(failures) if failures else 0}\n\n")
                f.write(response)

                # æŠŠåŸå§‹å †æ ˆä¹Ÿé™„åœ¨æœ€åï¼Œé˜²æ­¢LLMè¿˜æ˜¯è§£é‡Šä¸æ¸…
                # ä½¿ç”¨HTML <details>æ ‡ç­¾å®ç°æŠ˜å æ•ˆæœ
                f.write(f"\n\n<details><summary>ğŸ” Raw Traceback & Context (Click to expand)</summary>\n\n")
                f.write(f"```text\n{context}\n```\n")
                f.write(f"</details>\n")

            self.logger.info("Fatal error analysis completed and written to journal")

        except Exception as e:
            self.logger.error(f"Reporter itself crashed during diagnosis: {e}")
            # æœ€åçš„é˜²çº¿ï¼šç›´æ¥å†™å…¥åŸå§‹ä¸Šä¸‹æ–‡ï¼Œä¸ä¾èµ–LLM
            self._append_markdown(f"## ğŸ›‘ FATAL ERROR ANALYSIS\n\n**Reporter Failed**: {e}\n\n**Raw Context**:\n```text\n{context}\n```")

    # ========================================================================
    # æ ¸å¿ƒæ¥å£ï¼šç»“æœåˆ†æ
    # ========================================================================

    def summarize_results(self, solution_content: Any):
        """
        ç»“æœåˆ†æï¼šæ€»ç»“è®¡ç®—ç»“æœå¹¶è¿›è¡Œçµæ•åº¦è®¨è®º

        Args:
            solution_content: ç»“æœæ•°æ® (dict æˆ– JSON å­—ç¬¦ä¸²)
        """
        self.logger.info("LatentReporter summarizing results")

        # è½¬æ¢ä¸º JSON å­—ç¬¦ä¸²
        if isinstance(solution_content, dict):
            solution_str = json.dumps(solution_content, indent=2, ensure_ascii=False)
        elif isinstance(solution_content, str):
            solution_str = solution_content
        else:
            solution_str = str(solution_content)

        # 1. å°è¯•å¯»æ‰¾å›¾è¡¨
        charts_dir = self.root_dir / "Workspace" / "charts"
        chart_md = ""
        if charts_dir.exists():
            chart_md = "\n### Visualizations\n"
            chart_files = list(charts_dir.glob("*.png")) + list(charts_dir.glob("*.jpg"))
            for chart in chart_files:
                # ä½¿ç”¨ç›¸å¯¹è·¯å¾„å¼•ç”¨ï¼Œç¡®ä¿ Markdown å¯ç§»æ¤
                rel_path = f"../Workspace/charts/{chart.name}"
                chart_md += f"\n![{chart.stem}]({rel_path})\n*{chart.stem}*\n"

        # 2. è°ƒç”¨ LLM ç”Ÿæˆç»“æœåˆ†æ
        prompt = journal_prompts.RESULT_VALIDATION.format(solution=solution_str)

        try:
            response = self.llm.chat(
                prompt,
                system_prompt=journal_prompts.SYSTEM_PROMPT
            )
            self._append_markdown(f"## 4. Computational Experiments & Validation\n{chart_md}\n\n{response}")
            self.logger.info("Result summarization completed")
        except Exception as e:
            self.logger.error(f"Failed to generate result summary: {e}")
            self._append_markdown(f"## 4. Computational Experiments & Validation\n{chart_md}\n\n**Result Data**:\n```json\n{solution_str[:1000]}\n```\n\n[LLM Analysis Failed: {e}]")

    # ========================================================================
    # æ ¸å¿ƒæ¥å£ï¼šæ—¥è®°ç»ˆç»“
    # ========================================================================

    def finalize_journal(self):
        """
        åœ¨å®éªŒç»“æŸæ—¶è°ƒç”¨ï¼Œæ·»åŠ æ€»ç»“ä¿¡æ¯

        This method adds a concluding section to the journal with summary statistics.
        """
        try:
            footer = f"""

## ğŸ å®éªŒç»“æŸ

**ç»“æŸæ—¶é—´**: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}

---

*æœ¬æ—¥å¿—ç”± MM-Agent Latent Reporter è‡ªåŠ¨ç”Ÿæˆ*
*For detailed execution traces, see: `../Memory/logs/trace.jsonl`*
"""
            with open(self.journal_path, "a", encoding='utf-8') as f:
                f.write(footer)

            self.logger.info("Research journal finalized")

        except Exception as e:
            self.logger.error(f"Failed to finalize journal: {e}")

    # ========================================================================
    # å‘åå…¼å®¹æ–¹æ³•ï¼ˆä¿æŒä¸æ—§ç‰ˆ main.py çš„å…¼å®¹æ€§ï¼‰
    # ========================================================================

    def log_thought(self, stage: str, raw_content: str, status: str = "INFO", artifact: dict = None):
        """
        å‘åå…¼å®¹æ–¹æ³•ï¼šå®æ—¶è®°å½•æ€è€ƒäº‹ä»¶ï¼ˆä¸è°ƒç”¨ LLMï¼Œå¿«é€Ÿå†™å…¥ï¼‰

        è¿™æ˜¯æ—§ç‰ˆ LatentReporter çš„æ¥å£ï¼Œä¿ç•™ç”¨äºå‘åå…¼å®¹ã€‚
        æ–°æ¶æ„æ¨èä½¿ç”¨ reflect_on_stage() è¿›è¡Œæ·±åº¦åˆ†æã€‚
        """
        # ç›´æ¥å†™å…¥ï¼Œä¸è°ƒç”¨ LLMï¼ˆå¿«é€Ÿè·¯å¾„ï¼‰
        timestamp = datetime.now().strftime('%H:%M:%S')
        status_icons = {
            "SUCCESS": "âœ…",
            "WARNING": "âš ï¸",
            "ERROR": "âŒ",
            "INFO": "â„¹ï¸",
            "THINKING": "ğŸ§ "
        }
        icon = status_icons.get(status, "ğŸ“")

        entry = f"### {icon} [{timestamp}] {stage}\n\n{raw_content}\n"

        # åµŒå…¥äº§ç‰©
        if artifact:
            if artifact.get('type') == 'image':
                img_path = artifact.get('path')
                desc = artifact.get('description', 'Figure')
                if img_path and os.path.exists(img_path):
                    try:
                        rel_path = os.path.relpath(img_path, self.report_dir)
                        entry += f"\n![{desc}]({rel_path})\n*{desc}*\n"
                    except (ValueError, Exception):
                        entry += f"\n> [å›¾ç‰‡å·²ç”Ÿæˆ: {os.path.basename(img_path)}]\n"

            elif artifact.get('type') == 'code':
                code_path = artifact.get('path')
                if code_path:
                    entry += f"\n> ğŸ“„ **Generated Script**: `{os.path.basename(code_path)}`\n"

            elif artifact.get('type') == 'data':
                data_path = artifact.get('path')
                desc = artifact.get('description', 'Data file')
                if data_path:
                    entry += f"\n> ğŸ“Š **Data Output**: [{desc}]({os.path.basename(data_path)})\n"

        entry += "\n---\n"

        try:
            with open(self.journal_path, "a", encoding='utf-8') as f:
                f.write(entry)
            self.logger.debug(f"Journal entry added: {stage} [{status}]")
        except Exception as e:
            self.logger.error(f"Failed to write journal entry: {e}")

    def log_success(self, stage: str, achievement: str, artifact: dict = None):
        """å‘åå…¼å®¹æ–¹æ³•ï¼šè®°å½•æˆåŠŸäº‹ä»¶"""
        self.log_thought(stage, achievement, "SUCCESS", artifact)

    def log_error_analysis(self, error_type: str, error_message: str, attempted_fix: str = None):
        """å‘åå…¼å®¹æ–¹æ³•ï¼šè®°å½•é”™è¯¯åˆ†æ"""
        content = f"**é”™è¯¯ç±»å‹**: {error_type}\n**é”™è¯¯è¯¦æƒ…**: {error_message}"
        if attempted_fix:
            content += f"\n**å°è¯•ä¿®å¤**: {attempted_fix}"
        self.log_thought("Error Analysis", content, "ERROR")


# ============================================================================
# ä¾¿æ·å‡½æ•°ï¼šç”¨äºå¿«é€Ÿåˆ›å»ºå’Œåˆå§‹åŒ– LatentReporter
# ============================================================================

def create_latent_reporter(output_dir: str, llm_client, task_id: str = "Unknown") -> LatentReporter:
    """
    åˆ›å»ºå¹¶åˆå§‹åŒ–ä¸€ä¸ª LatentReporter å®ä¾‹

    Args:
        output_dir: è¾“å‡ºç›®å½•è·¯å¾„
        llm_client: LLM å®ä¾‹
        task_id: ä»»åŠ¡ ID (ä¿ç•™ç”¨äºå…¼å®¹æ€§ï¼Œå½“å‰æœªä½¿ç”¨)

    Returns:
        LatentReporter: åˆå§‹åŒ–å®Œæˆçš„æŠ¥å‘Šå™¨å®ä¾‹
    """
    return LatentReporter(output_dir, llm_client)
