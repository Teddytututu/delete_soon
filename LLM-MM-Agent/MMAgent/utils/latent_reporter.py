"""
Latent Reporter: Post-Processing Research Journal Generator

This module implements an observer-pattern reporter that reads execution traces
and generates MCM/ICM-style research journal entries using LLM.

Key Features:
- Reads trace.jsonl for comprehensive event analysis
- Stage-level retrospection (problem_analysis, mathematical_modeling)
- Error diagnosis and solution documentation
- Result validation and sensitivity discussion
- Automatic chart embedding with generated captions

Author: MM-Agent Team
Date: 2026-01-18 (Refactored for chat with claude3.txt proposal)
"""

import json
import os
import sys
import io
from pathlib import Path
import logging
from datetime import datetime
from typing import Optional, List, Dict, Any

# [FIX 2026-01-18] Windows Console Encoding Fix
# Set UTF-8 encoding for stdout/stderr on Windows to display emoji characters
# This prevents UnicodeEncodeError when printing emoji (ğŸ›‘, ğŸŸ¢, ğŸ”´) in error messages
if sys.platform == 'win32':
    try:
        # Reconfigure stdout and stderr with UTF-8 encoding
        # Use 'replace' error handler to prevent crashes on unencodable characters
        if hasattr(sys.stdout, 'buffer'):
            sys.stdout = io.TextIOWrapper(
                sys.stdout.buffer,
                encoding='utf-8',
                errors='replace',
                line_buffering=sys.stdout.line_buffering
            )
        if hasattr(sys.stderr, 'buffer'):
            sys.stderr = io.TextIOWrapper(
                sys.stderr.buffer,
                encoding='utf-8',
                errors='replace',
                line_buffering=sys.stderr.line_buffering
            )
    except Exception as e:
        # If reconfiguration fails, continue silently (non-critical)
        pass

# Import journal prompts
from MMAgent.prompt import journal_prompts

logger = logging.getLogger("LatentReporter")


class LatentReporter:
    """
    æ½œä¼æŠ¥å‘Šå™¨ï¼šè§‚å¯Ÿè€…æ¨¡å¼çš„ç§‘ç ”æ—¥è®°ç”Ÿæˆå™¨

    æ ¸å¿ƒèŒè´£ï¼š
    1. è§‚å¯Ÿ Agent æ‰§è¡Œè¿‡ç¨‹ï¼ˆè¯»å– trace.jsonlï¼‰
    2. è°ƒç”¨ LLM å°†æŠ€æœ¯æ—¥å¿—è½¬åŒ–ä¸ºç§‘ç ”é£æ ¼çš„å™è¿°
    3. è‡ªåŠ¨åµŒå…¥å›¾è¡¨ç­‰äº§ç‰©
    4. ç”Ÿæˆ Markdown æ ¼å¼çš„å®éªŒæ—¥è®°

    Usage:
        reporter = LatentReporter(output_dir, llm_client, tracker_file="path/to/trace.jsonl")
        reporter.reflect_on_stage("problem_analysis")
        reporter.reflect_on_stage("mathematical_modeling")
        reporter.diagnose_failure("KeyError: 'YEAR'")
        reporter.summarize_results(solution_dict)
    """

    def __init__(self, output_dir, llm_client, tracker_file=None, task_id="Unknown"):
        """
        åˆå§‹åŒ–æ½œä¼æŠ¥å‘Šå™¨

        Args:
            output_dir: ä¸»è¾“å‡ºç›®å½• (ä¾‹å¦‚ output/MM-Agent/Task_Timestamp/)
            llm_client: LLM å®ä¾‹ (ç”¨äºç”Ÿæˆå™è¿°)
            tracker_file: trace.jsonl çš„è·¯å¾„ (å¯é€‰ï¼Œé»˜è®¤è‡ªåŠ¨å®šä½)
            task_id: ä»»åŠ¡ID (å¯é€‰ï¼Œç”¨äºæ—¥å¿—æ ‡è¯†)
        """
        # --- è·¯å¾„ä¿®æ­£é€»è¾‘ (åé€’å½’ Bug ä¿®å¤) ---
        base_path = Path(output_dir)
        if base_path.name in ["Workspace", "Memory", "Report", "logs", "code", "json"]:
            self.root_dir = base_path.parent
        else:
            self.root_dir = base_path

        self.report_dir = self.root_dir / "Report"
        self.report_dir.mkdir(parents=True, exist_ok=True)

        # å®šä¹‰æ ¸å¿ƒæ–‡ä»¶è·¯å¾„
        self.journal_path = self.report_dir / "01_Research_Journal.md"

        # è‡ªåŠ¨å®šä½ trace.jsonl (å¦‚æœæœªä¼ å…¥)
        if tracker_file:
            self.trace_file = Path(tracker_file)
        else:
            self.trace_file = self.root_dir / "Memory" / "logs" / "trace.jsonl"

        self.llm = llm_client
        self.logger = logging.getLogger("main")
        self.task_id = task_id  # Store task_id for reference

        # åˆå§‹åŒ–æ—¥è®°æ–‡ä»¶å¤´
        if not self.journal_path.exists():
            self._init_journal()

    def _init_journal(self):
        """å†™å…¥æ—¥è®°çš„å¤´éƒ¨ä¿¡æ¯"""
        header = f"""# 2025_C æ•°å­¦å»ºæ¨¡ç§‘ç ”æ—¥è®°
**Task ID**: Auto-Generated
**Status**: In Progress

> æœ¬æ–‡æ¡£ç”± Latent LLM å®æ—¶ç”Ÿæˆï¼Œè®°å½•äº† Agent çš„æ€ç»´å®éªŒè¿‡ç¨‹ã€‚

---

## 1. Problem Background
[å¾…ç”Ÿæˆ]

"""
        try:
            with open(self.journal_path, 'w', encoding='utf-8') as f:
                f.write(header)
            self.logger.info(f"Research journal initialized: {self.journal_path}")
        except Exception as e:
            self.logger.error(f"Failed to initialize journal: {e}")

    def _read_recent_events(self, k=50) -> List[Dict[str, Any]]:
        """
        è¯»å– trace.jsonl çš„æœ€å k è¡Œ

        Args:
            k: è¯»å–çš„è¡Œæ•°

        Returns:
            List[Dict]: äº‹ä»¶åˆ—è¡¨
        """
        events = []
        if not self.trace_file.exists():
            self.logger.warning(f"Trace file not found: {self.trace_file}")
            return []

        try:
            with open(self.trace_file, 'r', encoding='utf-8') as f:
                lines = f.readlines()
                # ç®€å•ç­–ç•¥ï¼šå–æœ€è¿‘çš„ä¸Šä¸‹æ–‡
                # å®é™…ç”Ÿäº§ä¸­å¯æ ¹æ® stage è¿‡æ»¤
                for line in lines[-k:]:
                    try:
                        events.append(json.loads(line))
                    except json.JSONDecodeError:
                        continue
        except Exception as e:
            self.logger.warning(f"Failed to read trace events: {e}")

        return events

    # ========================================================================
    # [TRUTH MODE] CRITICAL FIX: _read_crash_site() for CRITICAL_FAILURE events
    # ========================================================================

    def _read_crash_site(self) -> List[Dict[str, Any]]:
        """
        ã€Truth Modeã€‘ä¸“é—¨è¯»å–CRITICAL_FAILUREäº‹ä»¶ï¼Œå®šä½å´©æºƒç‚¹

        ä¸_read_recent_events()ä¸åŒï¼Œæ­¤æ–¹æ³•åªè¯»å–"type": "CRITICAL_FAILURE"çš„äº‹ä»¶ï¼Œ
        è¿™äº›äº‹ä»¶åŒ…å«å®Œæ•´çš„Python tracebackï¼Œæ˜¯è¯Šæ–­Pipelineå´©æºƒçš„å…³é”®è¯æ®ã€‚

        Returns:
            List[Dict]: æ‰€æœ‰CRITICAL_FAILUREäº‹ä»¶çš„dataå­—æ®µåˆ—è¡¨

        Example:
            >>> crashes = reporter._read_crash_site()
            >>> if crashes:
            ...     last_crash = crashes[-1]
            ...     print(last_crash['error_type'])  # 'KeyError'
            ...     print(last_crash['traceback'])   # å®Œæ•´çš„å †æ ˆä¿¡æ¯
        """
        failures = []
        if not self.trace_file.exists():
            self.logger.error("Trace file not found for crash analysis")
            return []

        try:
            with open(self.trace_file, 'r', encoding='utf-8') as f:
                for line in f:
                    try:
                        event = json.loads(line)
                        # åªå…³å¿ƒCRITICAL_FAILUREç±»å‹çš„äº‹ä»¶
                        if event.get('type') == 'CRITICAL_FAILURE':
                            # æå–dataå­—æ®µï¼ŒåŒ…å«tracebackç­‰ä¿¡æ¯
                            failures.append(event.get('data', {}))
                    except json.JSONDecodeError:
                        # è·³è¿‡æ ¼å¼é”™è¯¯çš„è¡Œ
                        continue
        except Exception as e:
            self.logger.error(f"Failed to read crash site from trace file: {e}")

        return failures

    def _append_markdown(self, content: str):
        """
        è¿½åŠ å†…å®¹åˆ°æ—¥è®°æ–‡ä»¶

        Args:
            content: Markdown æ ¼å¼çš„å†…å®¹
        """
        try:
            with open(self.journal_path, 'a', encoding='utf-8') as f:
                f.write(f"\n\n{content}\n")
            self.logger.info(f"LatentReporter updated journal at {self.journal_path}")
        except Exception as e:
            self.logger.error(f"Failed to append to journal: {e}")

    # ========================================================================
    # æ ¸å¿ƒæ¥å£ï¼šé˜¶æ®µæ€§å¤ç›˜
    # ========================================================================

    def reflect_on_stage(self, stage_name: str):
        """
        é˜¶æ®µæ€§å¤ç›˜ï¼šè¯»å– trace.jsonl å¹¶ç”Ÿæˆé˜¶æ®µåˆ†æ

        Args:
            stage_name: é˜¶æ®µåç§°
                - "problem_analysis": é—®é¢˜åˆ†æé˜¶æ®µ
                - "mathematical_modeling": æ•°å­¦å»ºæ¨¡é˜¶æ®µ
        """
        self.logger.info(f"LatentReporter reflecting on stage: {stage_name}")

        # 1. è¯»å–æœ€è¿‘çš„äº‹ä»¶
        events = self._read_recent_events(k=100)  # è¯»å–è¶³å¤Ÿçš„ä¸Šä¸‹æ–‡
        events_str = json.dumps(events, indent=2, ensure_ascii=False)

        # 2. æ ¹æ®é˜¶æ®µé€‰æ‹© prompt
        if stage_name == "problem_analysis":
            prompt = journal_prompts.STAGE_REFLECTION_ANALYSIS.format(events=events_str)
            title = "## 2. Problem Restatement & Hypotheses"
        elif stage_name == "mathematical_modeling":
            prompt = journal_prompts.STAGE_REFLECTION_MODELING.format(events=events_str)
            title = "## 3. Modeling Process"
        else:
            self.logger.warning(f"Unknown stage: {stage_name}, skipping reflection")
            return

        # 3. è°ƒç”¨ LLM ç”Ÿæˆå†…å®¹
        try:
            response = self.llm.chat(
                prompt,
                system_prompt=journal_prompts.SYSTEM_PROMPT
            )
            self._append_markdown(f"{title}\n\n{response}")
            self.logger.info(f"Stage reflection completed: {stage_name}")
        except Exception as e:
            self.logger.error(f"Failed to generate stage reflection: {e}")
            # Fallback: å†™å…¥åŸå§‹äº‹ä»¶
            self._append_markdown(f"{title}\n\n[LLM Generation Failed: {e}]\n\n**Raw Events**:\n```json\n{events_str[:500]}\n```")

    # ========================================================================
    # æ ¸å¿ƒæ¥å£ï¼šé”™è¯¯è¯Šæ–­
    # ========================================================================

    def diagnose_failure(self, fallback_error_msg: str):
        """
        ã€Truth Modeã€‘å½“Pipelineå´©æºƒæ—¶è°ƒç”¨ï¼Œè¿›è¡Œæ³•åŒ»å¼å°¸æ£€åˆ†æ

        è¿™æ˜¯å®ç°"æ—¥å¿—ä¸è¯´è°"çš„æ ¸å¿ƒæ–¹æ³•ã€‚å®ƒä¼šï¼š
        1. è¯»å–trace.jsonlä¸­çš„CRITICAL_FAILUREäº‹ä»¶ï¼ˆåŒ…å«å®Œæ•´tracebackï¼‰
        2. å°†tracebackå–‚ç»™LLMè¿›è¡Œåˆ†æ
        3. åœ¨Research Journalä¸­ç”Ÿæˆè¯¦ç»†çš„é”™è¯¯æŠ¥å‘Š
        4. é™„åŠ åŸå§‹å †æ ˆä¿¡æ¯ä¾›äººå·¥éªŒè¯

        Args:
            fallback_error_msg: å¦‚æœæ‰¾ä¸åˆ°trace.jsonlæ—¶çš„å¤‡ç”¨é”™è¯¯ä¿¡æ¯
                                (é€šå¸¸æ˜¯main.py exceptå—æ•è·çš„str(e))

        Example:
            >>> try:
            ...     run_pipeline()
            ... except Exception as e:
            ...     reporter.diagnose_failure(str(e))
        """
        self.logger.warning(">>> LatentReporter: Starting Forensic Analysis (æ³•åŒ»å¼å°¸æ£€)...")

        # 1. è¯»å–æœ€è¯¦ç»†çš„å †æ ˆ
        failures = self._read_crash_site()

        # 2. æ„å»ºä¸Šä¸‹æ–‡
        context = ""
        if failures:
            # âœ… æ‰¾åˆ°äº†è®°å½•åœ¨æ¡ˆçš„åº•å±‚é”™è¯¯
            last_fail = failures[-1]
            context = f"""
!!! DETECTED CRITICAL FAILURE IN LOGS !!!

**Error Type**: {last_fail.get('error_type')}
**Error Message**: {last_fail.get('error_message')}
**Stage**: {last_fail.get('stage')}

--- RAW TRACEBACK (The Truth) ---
{last_fail.get('traceback')}
---------------------------------

**Context Snippet**:
{last_fail.get('context_snippet', 'No context available')}

**Analysis Time**: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}
"""
            self.logger.info(f"Found {len(failures)} critical failure(s) in trace, analyzing the most recent one")
        else:
            # âŒ æ—¥å¿—é‡Œæ²¡è®°ä¸‹æ¥ï¼Ÿç¨‹åºå´©æºƒå¾—å¤ªå¿«ï¼Œæˆ–è€…Trackerè¢«ç»•è¿‡äº†
            context = f"""
!!! SYSTEM CRASH (UNLOGGED) !!!

The system crashed without writing a structured error log to trace.jsonl.

**Python Exception detected by Main Loop**:
{fallback_error_msg}

**Possible Causes**:
1. tracker.log_error() was not called before exception bubbled up
2. Exception occurred before tracker initialization
3. File system error prevented writing to trace.jsonl
4. Exception occurred in ExecutionTracker.log_error() itself

**Analysis Time**: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}

**Note**: Analysis is based on fallback error message only, which may be incomplete.
"""
            self.logger.warning("No CRITICAL_FAILURE events found in trace, using fallback error message")

        # 3. è°ƒç”¨LLMè¿›è¡Œåˆ†æ
        prompt = journal_prompts.ERROR_DIAGNOSIS.format(events=context)

        try:
            response = self.llm.chat(
                prompt,
                system_prompt=journal_prompts.SYSTEM_PROMPT
            )

            # 4. ç‹ ç‹ åœ°å†™å…¥Markdownï¼Œç”¨çº¢è‰²è­¦å‘Š
            with open(self.journal_path, 'a', encoding='utf-8') as f:
                f.write(f"\n\n## ğŸ›‘ FATAL ERROR ANALYSIS\n")
                f.write(f"> **Status**: MISSION FAILED\n")
                f.write(f"> **Analysis Time**: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
                f.write(f"> **Crash Events Found**: {len(failures) if failures else 0}\n\n")
                f.write(response)

                # æŠŠåŸå§‹å †æ ˆä¹Ÿé™„åœ¨æœ€åï¼Œé˜²æ­¢LLMè¿˜æ˜¯è§£é‡Šä¸æ¸…
                # ä½¿ç”¨HTML <details>æ ‡ç­¾å®ç°æŠ˜å æ•ˆæœ
                f.write(f"\n\n<details><summary>ğŸ” Raw Traceback & Context (Click to expand)</summary>\n\n")
                f.write(f"```text\n{context}\n```\n")
                f.write(f"</details>\n")

            self.logger.info("Fatal error analysis completed and written to journal")

        except Exception as e:
            self.logger.error(f"Reporter itself crashed during diagnosis: {e}")
            # æœ€åçš„é˜²çº¿ï¼šç›´æ¥å†™å…¥åŸå§‹ä¸Šä¸‹æ–‡ï¼Œä¸ä¾èµ–LLM
            self._append_markdown(f"## ğŸ›‘ FATAL ERROR ANALYSIS\n\n**Reporter Failed**: {e}\n\n**Raw Context**:\n```text\n{context}\n```")

    # ========================================================================
    # æ ¸å¿ƒæ¥å£ï¼šç»“æœåˆ†æ
    # ========================================================================

    def summarize_results(self, solution_content: Any):
        """
        ç»“æœåˆ†æï¼šæ€»ç»“è®¡ç®—ç»“æœå¹¶è¿›è¡Œçµæ•åº¦è®¨è®º

        Args:
            solution_content: ç»“æœæ•°æ® (dict æˆ– JSON å­—ç¬¦ä¸²)
        """
        self.logger.info("LatentReporter summarizing results")

        # è½¬æ¢ä¸º JSON å­—ç¬¦ä¸²
        if isinstance(solution_content, dict):
            solution_str = json.dumps(solution_content, indent=2, ensure_ascii=False)
        elif isinstance(solution_content, str):
            solution_str = solution_content
        else:
            solution_str = str(solution_content)

        # 1. å°è¯•å¯»æ‰¾å›¾è¡¨
        charts_dir = self.root_dir / "Workspace" / "charts"
        chart_md = ""
        if charts_dir.exists():
            chart_md = "\n### Visualizations\n"
            chart_files = list(charts_dir.glob("*.png")) + list(charts_dir.glob("*.jpg"))
            for chart in chart_files:
                # ä½¿ç”¨ç›¸å¯¹è·¯å¾„å¼•ç”¨ï¼Œç¡®ä¿ Markdown å¯ç§»æ¤
                rel_path = f"../Workspace/charts/{chart.name}"
                chart_md += f"\n![{chart.stem}]({rel_path})\n*{chart.stem}*\n"

        # 2. è°ƒç”¨ LLM ç”Ÿæˆç»“æœåˆ†æ
        prompt = journal_prompts.RESULT_VALIDATION.format(solution=solution_str)

        try:
            response = self.llm.chat(
                prompt,
                system_prompt=journal_prompts.SYSTEM_PROMPT
            )
            self._append_markdown(f"## 4. Computational Experiments & Validation\n{chart_md}\n\n{response}")
            self.logger.info("Result summarization completed")
        except Exception as e:
            self.logger.error(f"Failed to generate result summary: {e}")
            self._append_markdown(f"## 4. Computational Experiments & Validation\n{chart_md}\n\n**Result Data**:\n```json\n{solution_str[:1000]}\n```\n\n[LLM Analysis Failed: {e}]")

    # ========================================================================
    # æ ¸å¿ƒæ¥å£ï¼šæ—¥è®°ç»ˆç»“
    # ========================================================================

    def finalize_journal(self):
        """
        åœ¨å®éªŒç»“æŸæ—¶è°ƒç”¨ï¼Œæ·»åŠ æ€»ç»“ä¿¡æ¯

        This method adds a concluding section to the journal with summary statistics.
        """
        try:
            footer = f"""

## ğŸ å®éªŒç»“æŸ

**ç»“æŸæ—¶é—´**: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}

---

*æœ¬æ—¥å¿—ç”± MM-Agent Latent Reporter è‡ªåŠ¨ç”Ÿæˆ*
*For detailed execution traces, see: `../Memory/logs/trace.jsonl`*
"""
            with open(self.journal_path, "a", encoding='utf-8') as f:
                f.write(footer)

            self.logger.info("Research journal finalized")

        except Exception as e:
            self.logger.error(f"Failed to finalize journal: {e}")

    # ========================================================================
    # å‘åå…¼å®¹æ–¹æ³•ï¼ˆä¿æŒä¸æ—§ç‰ˆ main.py çš„å…¼å®¹æ€§ï¼‰
    # ========================================================================

    def log_thought(self, stage: str, raw_content: str, status: str = "INFO", artifact: dict = None):
        """
        å‘åå…¼å®¹æ–¹æ³•ï¼šå®æ—¶è®°å½•æ€è€ƒäº‹ä»¶ï¼ˆä¸è°ƒç”¨ LLMï¼Œå¿«é€Ÿå†™å…¥ï¼‰

        è¿™æ˜¯æ—§ç‰ˆ LatentReporter çš„æ¥å£ï¼Œä¿ç•™ç”¨äºå‘åå…¼å®¹ã€‚
        æ–°æ¶æ„æ¨èä½¿ç”¨ reflect_on_stage() è¿›è¡Œæ·±åº¦åˆ†æã€‚
        """
        # ç›´æ¥å†™å…¥ï¼Œä¸è°ƒç”¨ LLMï¼ˆå¿«é€Ÿè·¯å¾„ï¼‰
        timestamp = datetime.now().strftime('%H:%M:%S')
        status_icons = {
            "SUCCESS": "âœ…",
            "WARNING": "âš ï¸",
            "ERROR": "âŒ",
            "INFO": "â„¹ï¸",
            "THINKING": "ğŸ§ "
        }
        icon = status_icons.get(status, "ğŸ“")

        entry = f"### {icon} [{timestamp}] {stage}\n\n{raw_content}\n"

        # åµŒå…¥äº§ç‰©
        if artifact:
            if artifact.get('type') == 'image':
                img_path = artifact.get('path')
                desc = artifact.get('description', 'Figure')
                if img_path and os.path.exists(img_path):
                    try:
                        rel_path = os.path.relpath(img_path, self.report_dir)
                        entry += f"\n![{desc}]({rel_path})\n*{desc}*\n"
                    except (ValueError, Exception):
                        entry += f"\n> [å›¾ç‰‡å·²ç”Ÿæˆ: {os.path.basename(img_path)}]\n"

            elif artifact.get('type') == 'code':
                code_path = artifact.get('path')
                if code_path:
                    entry += f"\n> ğŸ“„ **Generated Script**: `{os.path.basename(code_path)}`\n"

            elif artifact.get('type') == 'data':
                data_path = artifact.get('path')
                desc = artifact.get('description', 'Data file')
                if data_path:
                    entry += f"\n> ğŸ“Š **Data Output**: [{desc}]({os.path.basename(data_path)})\n"

        entry += "\n---\n"

        try:
            with open(self.journal_path, "a", encoding='utf-8') as f:
                f.write(entry)
            self.logger.debug(f"Journal entry added: {stage} [{status}]")
        except Exception as e:
            self.logger.error(f"Failed to write journal entry: {e}")

    def log_success(self, stage: str, achievement: str, artifact: dict = None):
        """å‘åå…¼å®¹æ–¹æ³•ï¼šè®°å½•æˆåŠŸäº‹ä»¶"""
        self.log_thought(stage, achievement, "SUCCESS", artifact)

    def log_error_analysis(self, error_type: str, error_message: str, attempted_fix: str = None):
        """å‘åå…¼å®¹æ–¹æ³•ï¼šè®°å½•é”™è¯¯åˆ†æ"""
        content = f"**é”™è¯¯ç±»å‹**: {error_type}\n**é”™è¯¯è¯¦æƒ…**: {error_message}"
        if attempted_fix:
            content += f"\n**å°è¯•ä¿®å¤**: {attempted_fix}"
        self.log_thought("Error Analysis", content, "ERROR")

    # ========================================================================
    # [NEW] æ·±åº¦è°ƒè¯•æŠ¥å‘Šç³»ç»Ÿ (Forensic Mode)
    # ========================================================================

    def log_execution_failure(self, stage: str, script_name: str, code_content: str,
                             error_output: str, attempt: int):
        """
        [NEW] è®°å½•æ‰§è¡Œå¤±è´¥å¹¶ç”Ÿæˆæ·±åº¦è°ƒè¯•æŠ¥å‘Š ("1000å­—æŠ¥å‘Š")

        æ ¹æ®chat with claude2.txtçš„è¦æ±‚ï¼Œå®ç°"æ³•åŒ»éªŒå°¸"æ¨¡å¼çš„æ—¥å¿—è®°å½•ï¼Œ
        æä¾›è¯¦ç»†çš„ä»£ç ä¸Šä¸‹æ–‡ã€é”™è¯¯åˆ†æå’Œä¿®å¤å»ºè®®ã€‚

        Args:
            stage: å½“å‰é˜¶æ®µ (å¦‚ "Code Generation", "Chart Generation")
            script_name: è„šæœ¬æ–‡ä»¶å (å¦‚ "main1.py", "chart_1")
            code_content: å®Œæ•´çš„ä»£ç å†…å®¹
            error_output: å®Œæ•´çš„ Traceback/Error String
            attempt: å½“å‰é‡è¯•æ¬¡æ•°

        Example:
            >>> reporter.log_execution_failure(
            ...     stage="Code Execution",
            ...     script_name="main1.py",
            ...     code_content="import pandas as pd\\ndf = pd.read_csv...",
            ...     error_output="Traceback...\\nKeyError: 'YEAR'",
            ...     attempt=2
            ... )
        """
        try:
            # 1. æå–é”™è¯¯ä¸Šä¸‹æ–‡ (ä»£ç å®šä½)
            error_context = self._extract_error_context(code_content, error_output)

            # 2. è°ƒç”¨ LLM ç”Ÿæˆæ·±åº¦éªŒå°¸æŠ¥å‘Š
            analysis = self._generate_forensic_report(
                stage, script_name, code_content, error_output, error_context, attempt
            )

            # 3. æ ¼å¼åŒ– Markdown
            timestamp = datetime.now().strftime('%H:%M:%S')

            entry = f"### âŒ [{timestamp}] CRASH REPORT: {script_name} (Attempt {attempt})\n\n"

            # 3.1 æ‘˜è¦éƒ¨åˆ† (TL;DR)
            entry += f"**Stage**: {stage}\n"
            entry += f"**Error Signature**: `{error_context['error_type']}: {error_context['error_msg']}`\n\n"

            # 3.2 æ·±åº¦åˆ†ææ­£æ–‡ (LLM ç”Ÿæˆ)
            entry += f"{analysis}\n\n"

            # 3.3 æŠ€æœ¯ç»†èŠ‚æŠ˜å å— (ä¿ç•™åŸå§‹è¯æ®)
            entry += "<details>\n<summary>ğŸ” åŸå§‹å †æ ˆä¸ä»£ç ä¸Šä¸‹æ–‡ (ç‚¹å‡»å±•å¼€)</summary>\n\n"

            if error_context.get('line_number'):
                entry += f"**Suspect Line ({error_context['line_number']})**:\n"
                entry += f"```python\n{error_context['snippet']}\n```\n\n"

            entry += "**Full Traceback**:\n"
            # é™åˆ¶Tracebacké•¿åº¦é˜²æ­¢çˆ†ç‚¸
            tb_preview = error_output[-2000:] if len(error_output) > 2000 else error_output
            entry += f"```text\n{tb_preview}\n```\n"

            entry += "\n</details>\n\n"

            entry += "---\n"

            # 4. è½ç›˜
            with open(self.journal_path, "a", encoding='utf-8') as f:
                f.write(entry)

            self.logger.info(f"Generated deep crash report for {script_name}")

        except Exception as e:
            self.logger.error(f"Failed to log execution failure: {e}", exc_info=True)
            # Fallback: ä½¿ç”¨ç®€å•çš„log_thought
            self.log_thought(stage, f"Execution failed for {script_name}: {str(e)[:200]}...", "ERROR")

    def _extract_error_context(self, code: str, error_output: str) -> dict:
        """
        è§£æ Tracebackï¼Œæå–æŠ¥é”™è¡Œå·å’Œä»£ç ç‰‡æ®µ

        Args:
            code: å®Œæ•´çš„ä»£ç å†…å®¹
            error_output: Pythonè§£é‡Šå™¨çš„é”™è¯¯è¾“å‡º

        Returns:
            dict: åŒ…å« error_type, error_msg, line_number, snippet çš„å­—å…¸
        """
        import re

        context = {
            "error_type": "RuntimeError",
            "error_msg": "Unknown error",
            "line_number": None,
            "snippet": ""
        }

        try:
            # 1. æå–é”™è¯¯ç±»å‹å’Œæ¶ˆæ¯ (æœ€åä¸€è¡Œé€šå¸¸æ˜¯ "TypeError: ...")
            lines = error_output.strip().split('\n')
            if lines:
                last_line = lines[-1]
                if ':' in last_line:
                    context['error_type'], context['error_msg'] = last_line.split(':', 1)
                else:
                    context['error_msg'] = last_line

            # 2. æå–è¡Œå· (æŸ¥æ‰¾ "File "...", line X")
            # ä¼˜å…ˆæ‰¾æœ€åä¸€ä¸ªæåŠæˆ‘ä»¬è„šæœ¬çš„è¡Œå·
            line_matches = re.findall(r'line (\d+)', error_output)
            if line_matches:
                # é€šå¸¸ Traceback æœ€åå‡ºç°çš„ line number æ˜¯æœ€å†…å±‚çš„é”™è¯¯ä½ç½®
                context['line_number'] = int(line_matches[-1])

            # 3. æå–ä»£ç ç‰‡æ®µ
            if context['line_number']:
                code_lines = code.split('\n')
                target_idx = context['line_number'] - 1
                if 0 <= target_idx < len(code_lines):
                    # æå–å‰å 2 è¡Œ
                    start = max(0, target_idx - 2)
                    end = min(len(code_lines), target_idx + 3)

                    snippet = []
                    for i in range(start, end):
                        prefix = ">> " if i == target_idx else "   "
                        snippet.append(f"{prefix}{i+1}: {code_lines[i]}")
                    context['snippet'] = '\n'.join(snippet)

        except Exception as e:
            self.logger.warning(f"Error context extraction failed: {e}")

        return context

    def _generate_forensic_report(self, stage, script, code, error, context, attempt):
        """
        ç”Ÿæˆè¯¦ç»†çš„"éªŒå°¸"æŠ¥å‘Š (æ·±åº¦æŠ€æœ¯åˆ†æ)

        ä½¿ç”¨ä¸“é—¨çš„Promptè¦æ±‚LLMè¿›è¡Œæ·±åº¦åˆ†æï¼Œè€Œä¸æ˜¯ç®€å•çš„æ€»ç»“ã€‚
        """
        # æ„å»ºä¸€ä¸ªè¦æ±‚æåº¦è¯¦ç»†çš„ Prompt
        prompt = f"""
You are a Senior Python Architect and Debugging Expert conducting a forensic analysis of a crash.
Your goal is to write a detailed Technical Post-Mortem Report in Chinese.

## Incident Context
- **Script**: {script}
- **Stage**: {stage}
- **Attempt**: {attempt}
- **Error**: {context['error_type']}: {context['error_msg']}

## Suspect Code Snippet
```python
{context.get('snippet', 'Code snippet unavailable')}
```

## Raw Traceback (Partial)
{error[:1000] if len(error) > 1000 else error}
...

## Report Requirements (Generate detailed Markdown)

Please generate a structured report covering the following sections. Do not be brief. Be analytical and critical.

1. **ğŸ”´ æ ¹æœ¬åŸå› åˆ†æ**:
   - Explain EXACTLY why the code crashed.
   - Was it a syntax error, logic error, or data error?
   - If variable types were wrong, explain the mismatch.
   - If files were missing, explain the pathing issue.

2. **ğŸ§ ä»£ç é€»è¾‘æ¼æ´**:
   - Analyze the specific lines of code.
   - Point out bad practices (e.g., hardcoded paths, lack of try-except, assumption of column names).
   - Why did the previous checks fail to catch this?

3. **ğŸ’¥ æ½œåœ¨å‰¯ä½œç”¨**:
   - How does this failure affect the downstream pipeline?
   - Are there corrupted artifacts left behind?

4. **ğŸ› ï¸ ä¿®å¤å»ºè®®**:
   - Provide concrete code corrections.
   - Suggest defensive programming techniques to prevent recurrence.
   - **Crucial**: Provide the CORRECTED code block for the specific crashing lines.

**Tone**: Highly technical, critical, and educational. Like a senior engineer reviewing a junior's broken code.

Output your analysis in Chinese:
"""

        try:
            # ä½¿ç”¨ llm.generate() æ–¹æ³•ç”ŸæˆéªŒå°¸æŠ¥å‘Š
            # system å‚æ•°ç”¨äºè®¾å®šç³»ç»Ÿæç¤ºè¯
            report = self.llm.generate(
                prompt,
                system="You are a merciless code auditor. Your job is to analyze crashes thoroughly and provide actionable debugging insights."
            )
            return report.strip()
        except Exception as e:
            return f"**[System Error]** Failed to generate forensic report: {e}"


# ============================================================================
# ä¾¿æ·å‡½æ•°ï¼šç”¨äºå¿«é€Ÿåˆ›å»ºå’Œåˆå§‹åŒ– LatentReporter
# ============================================================================

def create_latent_reporter(output_dir: str, llm_client, task_id: str = "Unknown") -> LatentReporter:
    """
    åˆ›å»ºå¹¶åˆå§‹åŒ–ä¸€ä¸ª LatentReporter å®ä¾‹

    Args:
        output_dir: è¾“å‡ºç›®å½•è·¯å¾„
        llm_client: LLM å®ä¾‹
        task_id: ä»»åŠ¡ ID (ç”¨äºæ—¥å¿—æ ‡è¯†å’ŒæŠ¥å‘Šç”Ÿæˆ)

    Returns:
        LatentReporter: åˆå§‹åŒ–å®Œæˆçš„æŠ¥å‘Šå™¨å®ä¾‹
    """
    return LatentReporter(output_dir, llm_client, task_id=task_id)
